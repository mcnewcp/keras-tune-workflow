{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This notebook works through an example workflow using [hyperopt](http://hyperopt.github.io/hyperopt/) to tune a Keras model, while tracking the results with MLFlow.\n",
    "\n",
    "# Data\n",
    "\n",
    "The CA housing data will be used for this example, which is a simple regressiont task. It will be loaded from the `sklearn` data loader.  I'll split off 20% into a test set and an additional 20% into a validation set.  Finally, I'll standardize the data using `StandardScaler` ahead of modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "      <td>1.320900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.951585e-15</td>\n",
       "      <td>-1.221086e-16</td>\n",
       "      <td>-1.939751e-15</td>\n",
       "      <td>-1.531414e-14</td>\n",
       "      <td>5.648193e-17</td>\n",
       "      <td>-8.122640e-17</td>\n",
       "      <td>2.069821e-14</td>\n",
       "      <td>6.596014e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "      <td>1.000038e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.780359e+00</td>\n",
       "      <td>-2.195702e+00</td>\n",
       "      <td>-1.868116e+00</td>\n",
       "      <td>-1.783648e+00</td>\n",
       "      <td>-1.259356e+00</td>\n",
       "      <td>-1.968599e-01</td>\n",
       "      <td>-1.438172e+00</td>\n",
       "      <td>-2.398818e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.873717e-01</td>\n",
       "      <td>-8.438056e-01</td>\n",
       "      <td>-4.103394e-01</td>\n",
       "      <td>-2.085559e-01</td>\n",
       "      <td>-5.651305e-01</td>\n",
       "      <td>-5.433696e-02</td>\n",
       "      <td>-7.922602e-01</td>\n",
       "      <td>-1.106712e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.752336e-01</td>\n",
       "      <td>3.095082e-02</td>\n",
       "      <td>-7.775169e-02</td>\n",
       "      <td>-1.075282e-01</td>\n",
       "      <td>-2.264624e-01</td>\n",
       "      <td>-2.285411e-02</td>\n",
       "      <td>-6.424836e-01</td>\n",
       "      <td>5.409723e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.673025e-01</td>\n",
       "      <td>6.671373e-01</td>\n",
       "      <td>2.605153e-01</td>\n",
       "      <td>9.533632e-03</td>\n",
       "      <td>2.686508e-01</td>\n",
       "      <td>1.508449e-02</td>\n",
       "      <td>9.769765e-01</td>\n",
       "      <td>7.763558e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.877788e+00</td>\n",
       "      <td>1.859987e+00</td>\n",
       "      <td>5.619934e+01</td>\n",
       "      <td>5.747692e+01</td>\n",
       "      <td>3.045367e+01</td>\n",
       "      <td>1.017102e+02</td>\n",
       "      <td>2.961517e+00</td>\n",
       "      <td>2.509179e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  1.320900e+04  1.320900e+04  1.320900e+04  1.320900e+04  1.320900e+04   \n",
       "mean   1.951585e-15 -1.221086e-16 -1.939751e-15 -1.531414e-14  5.648193e-17   \n",
       "std    1.000038e+00  1.000038e+00  1.000038e+00  1.000038e+00  1.000038e+00   \n",
       "min   -1.780359e+00 -2.195702e+00 -1.868116e+00 -1.783648e+00 -1.259356e+00   \n",
       "25%   -6.873717e-01 -8.438056e-01 -4.103394e-01 -2.085559e-01 -5.651305e-01   \n",
       "50%   -1.752336e-01  3.095082e-02 -7.775169e-02 -1.075282e-01 -2.264624e-01   \n",
       "75%    4.673025e-01  6.671373e-01  2.605153e-01  9.533632e-03  2.686508e-01   \n",
       "max    5.877788e+00  1.859987e+00  5.619934e+01  5.747692e+01  3.045367e+01   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  1.320900e+04  1.320900e+04  1.320900e+04  \n",
       "mean  -8.122640e-17  2.069821e-14  6.596014e-14  \n",
       "std    1.000038e+00  1.000038e+00  1.000038e+00  \n",
       "min   -1.968599e-01 -1.438172e+00 -2.398818e+00  \n",
       "25%   -5.433696e-02 -7.922602e-01 -1.106712e+00  \n",
       "50%   -2.285411e-02 -6.424836e-01  5.409723e-01  \n",
       "75%    1.508449e-02  9.769765e-01  7.763558e-01  \n",
       "max    1.017102e+02  2.961517e+00  2.509179e+00  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, test_size=0.2\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train, columns=housing.feature_names).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = (X_train, {\"main_output\": y_train, \"aux_output\": y_train})\n",
    "val_data = (X_valid, {\"main_output\": y_valid, \"aux_output\": y_valid})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The model used for this example will be a wide and deep network with the following characteristics:\n",
    "- a deep path with `n_hidden` hidden layers with `n_neurons` at each layer\n",
    "- a wide path connecting all inputs to the output\n",
    "- all layers are fully connected\n",
    "- two outpus:\n",
    "    - one from the deep path alone, fit to the target\n",
    "    - one from the concatenaded wide and deep paths, fit to the target\n",
    "\n",
    "This type of multi-output architecture is usually used as a regularization technique, but I'm simply employing it here so my example has more than one loss to simultaneously minimize.  This model is very similar to the regression example I used in my [intro to Keras](https://github.com/mcnewcp/book-geron-ml-sklearn-keras-tensorflow/blob/main/10-intro-ann-keras/10-intro-ann-keras.ipynb) notebook and from Chapter 10 of [Hands on ML](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), so I won't explain the Keras code below.\n",
    "\n",
    "The model build code should be functionalized so that the hyperparameters are generalized in the build and compile steps for integration into hyperparameter tuning.  I'm pulling out the following hyperparameters for tuning:\n",
    "- `n_hidden`: number of hidden layers\n",
    "- `n_neurons`: number of neurons per layer\n",
    "- `activation`: activation funciton used in hidden layers\n",
    "\n",
    "*Note*: I'm not tuning learning rate here.  In general I think it's best practice to choose a sufficiently low learning rate, high number of epochs, and use early stopping.  The goal of this stage of hyperparameter tuning is to simply identify promising model candidates.  Once promising candidates have been identified, the learning rate will be fine tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 16:01:54.831442: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf version: 2.11.0 , keras version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"tf version:\", tf.__version__, \", keras version:\", keras.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=20, activation=\"relu\"):\n",
    "    inp = keras.layers.Input(shape=[8], name=\"input\")  # input layer\n",
    "    for layer in range(n_hidden):  # sequentially add hidden layers\n",
    "        if layer == 0:\n",
    "            hl = keras.layers.Dense(n_neurons, activation=activation)(inp)\n",
    "        else:\n",
    "            hl = keras.layers.Dense(n_neurons, activation=activation)(hl)\n",
    "    concat = keras.layers.Concatenate()([hl, inp])  # concat deep and wide paths\n",
    "    main_output = keras.layers.Dense(1, name=\"main_output\")(concat)  # combined output\n",
    "    aux_output = keras.layers.Dense(1, name=\"aux_output\")(hl)  # deep output\n",
    "    model = keras.Model(inputs=[inp], outputs=[main_output, aux_output])\n",
    "    model.compile(\n",
    "        loss={\"main_output\": \"mse\", \"aux_output\": \"mse\"},\n",
    "        loss_weights={\n",
    "            \"main_output\": 0.9,\n",
    "            \"aux_output\": 0.1,\n",
    "        },  # weighting heavily towards main output\n",
    "        optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperopt with Validation Split\n",
    "\n",
    "[Hyperopt](http://hyperopt.github.io/hyperopt/) is an optimization library commonly used to tune hyperparameters during model experimentation, though it is an entirely general package.  It will search through an arbitrarily complex search space to minimize and objective function.  The steps of using hyperopt include:\n",
    "1. define objective function\n",
    "2. define search space\n",
    "3. run the minimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "Hyperopt works by changing values in your hyperparameter space and evaluating the objective function to receive a score (`loss`).  It then investigates promising areas of the search space more thoroughly.  The objective function should take in the chosen values of hyperparameters and output a loss for minimization and a status.  It can also output anything else you'd like to log in the trials object, but I won't include anything else here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import fit_eval_log\n",
    "from hyperopt import STATUS_OK\n",
    "\n",
    "def objective(hyper_params):\n",
    "    model = build_model(**hyper_params)\n",
    "    run_name = \"test-hp\"\n",
    "    mean_val_loss = fit_eval_log(\n",
    "        run_name=run_name,\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        model=model,\n",
    "        hyper_params=hyper_params,\n",
    "    )\n",
    "    return {\"loss\": mean_val_loss, \"status\": STATUS_OK}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space\n",
    "\n",
    "The hyperparameter search space needs to be set up in a way to inform hyperopt not only the bounds of the hyperparameters but also how to choose values in between the bounds.  This is done by using the most relevant parameter expression from `hyperopt.hp`.  The [documentation](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/) lists all options, but the most relevant in my experience are:\n",
    "- `hp.choice()` chooses an option from a supplied list\n",
    "- `hp.uniform()` samples a continuous value between a lower and upper bound\n",
    "- `hp.quniform()` samples an integer between a lower and upper bound\n",
    "\n",
    "*Note*: there is an uresolved type issue around using `hp.quniform()` which is resolved by wrapping it in `scope.int()` from `hyperopt.pyll`.\n",
    "\n",
    "Below, I'll set up the search space for my example which includes number of neurons per layer, number of hidden layers, and activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "hyper_params = {\n",
    "    \"n_hidden\": scope.int(hp.quniform(\"n_hidden\", 1, 10, 1)),\n",
    "    \"n_neurons\": scope.int(hp.quniform(\"n_neurons\", 3, 50, 1)),\n",
    "    \"activation\": hp.choice(\"activation\", [\"relu\", \"sigmoid\", \"tanh\"]),\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize Objective\n",
    "\n",
    "Now to run the optimization, I'll use `fmin()` and ask hyperopt to suggest the best optimization algorithm with `tpe.suggest`.  You simply supply the objective function along with the search space and tell hyperopt how many trials you want to run, then it'll return the best trial along with a history of the trials in a `Trials()` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s        \n",
      "1/1 [==============================] - 0s 101ms/step \n",
      "\n",
      "  0%|          | 0/10 [00:17<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpm3kianqu/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpm3kianqu/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                 \n",
      "1/1 [==============================] - 0s 68ms/step                           \n",
      "\n",
      " 10%|█         | 1/10 [00:45<04:35, 30.60s/trial, best loss: 0.548612654209137]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpz_7_yy1a/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpz_7_yy1a/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 98ms/step                            \n",
      "\n",
      " 20%|██        | 2/10 [01:17<03:41, 27.73s/trial, best loss: 0.5344837307929993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpg0ba1_yc/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpg0ba1_yc/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 76ms/step                            \n",
      "\n",
      " 30%|███       | 3/10 [01:42<03:23, 29.13s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpsdprups5/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpsdprups5/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 57ms/step                            \n",
      "\n",
      " 40%|████      | 4/10 [02:04<02:42, 27.06s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmp382k9inp/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmp382k9inp/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 78ms/step                            \n",
      "\n",
      " 50%|█████     | 5/10 [02:32<02:06, 25.29s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpegwkklit/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpegwkklit/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 163ms/step                           \n",
      "\n",
      " 60%|██████    | 6/10 [02:59<01:46, 26.74s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmp4gdkcc39/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmp4gdkcc39/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 80ms/step                            \n",
      "\n",
      " 70%|███████   | 7/10 [03:24<01:19, 26.62s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmprho3ao_7/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmprho3ao_7/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 71ms/step                            \n",
      "\n",
      " 80%|████████  | 8/10 [03:46<00:51, 25.58s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpiodnhpeh/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpiodnhpeh/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s                                  \n",
      "1/1 [==============================] - 0s 85ms/step                            \n",
      "\n",
      " 90%|█████████ | 9/10 [04:15<00:24, 24.77s/trial, best loss: 0.4567939043045044]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpyv2tq59p/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/m8/0_prp1tj41s9n5xm0bfqp6wm0000gn/T/tmpyv2tq59p/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:25<00:00, 26.53s/trial, best loss: 0.4567939043045044]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import Trials, fmin, tpe\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(experiment_name='test-hp')\n",
    "mlflow.tensorflow.autolog(silent=True)\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=hyper_params,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=10,\n",
    "    trials=trials,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Results\n",
    "\n",
    "The object returned by optimizationa above contains some info on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b06340917b32c233dd2dc2960a5f67050ebf8c214e1ba3d4b841fb841861705b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
